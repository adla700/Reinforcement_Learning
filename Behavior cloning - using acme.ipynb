{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9a195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec: Box([-3.4028235e+38 -3.4028235e+38 -3.1415927e+00 -3.4028235e+38], [3.4028235e+38 3.4028235e+38 3.1415927e+00 3.4028235e+38], (4,), float32)\n",
      "Action Spec: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "\n",
    "env = make_vec_env(\n",
    "    \"seals:seals/CartPole-v0\",\n",
    "    rng=np.random.default_rng(),\n",
    "    post_wrappers=[\n",
    "        lambda env, _: RolloutInfoWrapper(env)\n",
    "    ],  # needed for computing rollouts later\n",
    ")\n",
    "env_specs = env.observation_space, env.action_space \n",
    "print('Observation Spec:', env.observation_space)\n",
    "print('Action Spec:', env.action_space)\n",
    "\n",
    "expert = load_policy(\n",
    "    \"ppo-huggingface\",\n",
    "    organization=\"HumanCompatibleAI\",\n",
    "    env_name=\"seals/CartPole-v0\",\n",
    "    venv=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f5255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01369617, -0.02302133, -0.04590265, -0.04834723],\n",
       "       [ 0.00118216,  0.04504637, -0.03558404,  0.04486495],\n",
       "       [-0.02383879, -0.02015088,  0.03142257, -0.04080841],\n",
       "       [-0.04143508, -0.02631895,  0.03012745,  0.0082162 ],\n",
       "       [ 0.04430561,  0.00113276,  0.04762437, -0.0419164 ],\n",
       "       [ 0.03050029,  0.03079408,  0.00153256, -0.02141986],\n",
       "       [ 0.00381644, -0.01567291, -0.01309328, -0.01255032],\n",
       "       [ 0.01250955,  0.03972138,  0.02756857, -0.02747928]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5139c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "reward, _ = evaluate_policy(expert, env, 10)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70914698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.data import rollout\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rollouts = rollout.rollout(\n",
    "    expert,\n",
    "    env,\n",
    "    rollout.make_sample_until(min_timesteps=None, min_episodes=50),\n",
    "    rng=rng,\n",
    ")\n",
    "transitions = rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547fcf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `rollout` function generated a list of 56 <class 'imitation.data.types.TrajectoryWithRew'>.\n",
      "After flattening, this list is turned into a <class 'imitation.data.types.Transitions'> object containing 28000 transitions.\n",
      "The transitions object contains arrays for: obs, acts, infos, next_obs, dones.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\"\"The `rollout` function generated a list of {len(rollouts)} {type(rollouts[0])}.\n",
    "After flattening, this list is turned into a {type(transitions)} object containing {len(transitions)} transitions.\n",
    "The transitions object contains arrays for: {', '.join(transitions.__dict__.keys())}.\"\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d3bd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrajectoryWithRew(obs=array([[-0.04716803, -0.03757167,  0.01706244,  0.01471895],\n",
       "       [-0.04791947, -0.23293412,  0.01735682,  0.31273606],\n",
       "       [-0.05257815, -0.03806367,  0.02361154,  0.02557709],\n",
       "       ...,\n",
       "       [ 0.23058708, -0.0370378 , -0.01744288,  0.00292787],\n",
       "       [ 0.22984631, -0.23190531, -0.01738432,  0.2900567 ],\n",
       "       [ 0.22520821, -0.03653984, -0.01158319, -0.00805794]],\n",
       "      dtype=float32), acts=array([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1], dtype=int64), infos=None, terminal=True, rews=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollouts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753b7ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transitions(obs=array([[-0.04716803, -0.03757167,  0.01706244,  0.01471895],\n",
       "       [-0.04791947, -0.23293412,  0.01735682,  0.31273606],\n",
       "       [-0.05257815, -0.03806367,  0.02361154,  0.02557709],\n",
       "       ...,\n",
       "       [ 0.1094296 , -0.18791756, -0.00134319,  0.25827387],\n",
       "       [ 0.10567125,  0.00722354,  0.00382229, -0.0348324 ],\n",
       "       [ 0.10581572, -0.18795301,  0.00312564,  0.25905403]],\n",
       "      dtype=float32), acts=array([0, 1, 0, ..., 1, 0, 1], dtype=int64), infos=array([{}, {}, {}, ..., {}, {}, {}], dtype=object), next_obs=array([[-0.04791947, -0.23293412,  0.01735682,  0.31273606],\n",
       "       [-0.05257815, -0.03806367,  0.02361154,  0.02557709],\n",
       "       [-0.05333942, -0.23351614,  0.02412308,  0.3256152 ],\n",
       "       ...,\n",
       "       [ 0.10567125,  0.00722354,  0.00382229, -0.0348324 ],\n",
       "       [ 0.10581572, -0.18795301,  0.00312564,  0.25905403],\n",
       "       [ 0.10205666,  0.00712418,  0.00830672, -0.03264138]],\n",
       "      dtype=float32), dones=array([False, False, False, ..., False, False,  True]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe15cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adhula\\Downloads\\acme\n"
     ]
    }
   ],
   "source": [
    "cd acme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0491bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02cf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehaviorCloningAgent(acme.Actor):\n",
    "\n",
    "  def __init__(self, env_specs=None):\n",
    "    # No Q-value table needed for behavior cloning\n",
    "    pass\n",
    "\n",
    "  def transform_state(self, state):\n",
    "    # This might still be needed depending on your environment\n",
    "    state = *map(int, state),\n",
    "    return state\n",
    "\n",
    "  def select_action(self, observation):\n",
    "    state = self.transform_state(observation)\n",
    "    # Access expert action from rollout data (replace with your implementation)\n",
    "    expert_action = get_expert_action_from_rollout(state)\n",
    "    return expert_action\n",
    "\n",
    "  def observe_first(self, timestep):\n",
    "    pass  # No action needed here\n",
    "\n",
    "  def observe(self, action, next_timestep):\n",
    "    pass  # No action needed here\n",
    "\n",
    "  def update(self):\n",
    "    pass  # No update needed in behavior cloning\n",
    "\n",
    "bc=BehaviorCloningAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f054cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from acme import types\n",
    "from acme.types import Batches\n",
    "from acme.wrappers import gym_wrapper\n",
    "from acme.environment_loop import EnvironmentLoop\n",
    "from acme.utils.loggers import TerminalLogger, InMemoryLogger\n",
    "\n",
    "# environments\n",
    "import gym\n",
    "#import dm_env\n",
    "\n",
    "# other\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231b19e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyVecEnv' object has no attribute 'reward_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6100\\2889586290.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironmentLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mInMemoryLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\acme\\acme\\environment_loop.py\u001b[0m in \u001b[0;36mrun_episode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# accumulated during the episode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     episode_return = tree.map_structure(_generate_zeros_from_spec,\n\u001b[1;32m---> 95\u001b[1;33m                                         self._environment.reward_spec())\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0menv_reset_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mtimestep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_environment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DummyVecEnv' object has no attribute 'reward_spec'"
     ]
    }
   ],
   "source": [
    "loop = EnvironmentLoop(env, bc, logger=InMemoryLogger())\n",
    "loop.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc166b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acme123",
   "language": "python",
   "name": "acme123"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
